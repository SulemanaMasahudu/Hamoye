{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "from subprocess import check_output\n",
    "#print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "from keras import optimizers\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import fbeta_score\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = []\n",
    "x_test = []\n",
    "y_train = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('planet/train_classes.csv')\n",
    "df_test = pd.read_csv('planet/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "flatten = lambda l: [item for sublist in l for item in sublist]\n",
    "labels = list(set(flatten([l.split(' ') for l in df_train['tags'].values])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['blow_down',\n",
    " 'bare_ground',\n",
    " 'conventional_mine',\n",
    " 'blooming',\n",
    " 'cultivation',\n",
    " 'artisinal_mine',\n",
    " 'haze',\n",
    " 'primary',\n",
    " 'slash_burn',\n",
    " 'habitation',\n",
    " 'clear',\n",
    " 'road',\n",
    " 'selective_logging',\n",
    " 'partly_cloudy',\n",
    " 'agriculture',\n",
    " 'water',\n",
    " 'cloudy']\n",
    "\n",
    "label_map = {'agriculture': 14,\n",
    " 'artisinal_mine': 5,\n",
    " 'bare_ground': 1,\n",
    " 'blooming': 3,\n",
    " 'blow_down': 0,\n",
    " 'clear': 10,\n",
    " 'cloudy': 16,\n",
    " 'conventional_mine': 2,\n",
    " 'cultivation': 4,\n",
    " 'habitation': 9,\n",
    " 'haze': 6,\n",
    " 'partly_cloudy': 13,\n",
    " 'primary': 7,\n",
    " 'road': 11,\n",
    " 'selective_logging': 12,\n",
    " 'slash_burn': 8,\n",
    " 'water': 15}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 40479/40479 [01:14<00:00, 539.98it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████| 61191/61191 [01:52<00:00, 541.53it/s]\n"
     ]
    }
   ],
   "source": [
    "for f, tags in tqdm(df_train.values, miniters=1000):\n",
    "    img = cv2.imread('planet/train-jpg/{}.jpg'.format(f))\n",
    "    targets = np.zeros(17)\n",
    "    for t in tags.split(' '):\n",
    "        targets[label_map[t]] = 1 \n",
    "    x_train.append(cv2.resize(img, (64, 64)))\n",
    "    y_train.append(targets)\n",
    "\n",
    "for f, tags in tqdm(df_test.values, miniters=1000):\n",
    "    img = cv2.imread('planet/test-jpg/{}.jpg'.format(f))\n",
    "    x_test.append(cv2.resize(img, (64, 64)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40479, 64, 64, 3)\n",
      "(40479, 17)\n"
     ]
    }
   ],
   "source": [
    "y_train = np.array(y_train, np.uint8)\n",
    "x_train = np.array(x_train, np.float32)/255.\n",
    "x_test  = np.array(x_test, np.float32)/255.\n",
    "\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "nfolds = 5\n",
    "\n",
    "num_fold = 0\n",
    "sum_score = 0\n",
    "#input_channels=3\n",
    "\n",
    "yfull_test = []\n",
    "yfull_train =[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.vgg19 import VGG19\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 64\n",
    "input_channels = 3\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=nfolds, shuffle=True, random_state=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start KFold number 1 from 5\n",
      "Split train:  32383 32383\n",
      "Split valid:  8096 8096\n",
      "Train on 32383 samples, validate on 8096 samples\n",
      "Epoch 1/50\n",
      " - 501s - loss: 0.1884 - accuracy: 0.9256 - val_loss: 0.1618 - val_accuracy: 0.9320\n",
      "Epoch 2/50\n",
      " - 1058s - loss: 0.1542 - accuracy: 0.9371 - val_loss: 0.1441 - val_accuracy: 0.9414\n",
      "Epoch 3/50\n",
      " - 1058s - loss: 0.1421 - accuracy: 0.9419 - val_loss: 0.1366 - val_accuracy: 0.9445\n",
      "Epoch 4/50\n",
      " - 1058s - loss: 0.1364 - accuracy: 0.9447 - val_loss: 0.1346 - val_accuracy: 0.9459\n",
      "Epoch 5/50\n",
      " - 651s - loss: 0.1322 - accuracy: 0.9461 - val_loss: 0.1301 - val_accuracy: 0.9473\n",
      "Epoch 6/50\n",
      " - 1058s - loss: 0.1279 - accuracy: 0.9480 - val_loss: 0.1253 - val_accuracy: 0.9497\n",
      "Epoch 7/50\n",
      " - 1057s - loss: 0.1235 - accuracy: 0.9505 - val_loss: 0.1246 - val_accuracy: 0.9511\n",
      "Epoch 8/50\n",
      " - 1058s - loss: 0.1206 - accuracy: 0.9521 - val_loss: 0.1233 - val_accuracy: 0.9516\n",
      "Epoch 9/50\n",
      " - 1057s - loss: 0.1169 - accuracy: 0.9538 - val_loss: 0.1218 - val_accuracy: 0.9522\n",
      "Epoch 10/50\n",
      " - 1057s - loss: 0.1130 - accuracy: 0.9552 - val_loss: 0.1199 - val_accuracy: 0.9530\n",
      "Epoch 11/50\n",
      " - 1057s - loss: 0.1109 - accuracy: 0.9564 - val_loss: 0.1136 - val_accuracy: 0.9557\n",
      "Epoch 12/50\n",
      " - 975s - loss: 0.1073 - accuracy: 0.9583 - val_loss: 0.1205 - val_accuracy: 0.9551\n",
      "Epoch 13/50\n",
      " - 1061s - loss: 0.1053 - accuracy: 0.9585 - val_loss: 0.1141 - val_accuracy: 0.9562\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 14/50\n",
      " - 1061s - loss: 0.0900 - accuracy: 0.9647 - val_loss: 0.1078 - val_accuracy: 0.9586\n",
      "Epoch 15/50\n",
      " - 674s - loss: 0.0853 - accuracy: 0.9666 - val_loss: 0.1084 - val_accuracy: 0.9590\n",
      "Epoch 16/50\n",
      " - 1058s - loss: 0.0826 - accuracy: 0.9678 - val_loss: 0.1096 - val_accuracy: 0.9589\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "Epoch 17/50\n",
      " - 1057s - loss: 0.0786 - accuracy: 0.9691 - val_loss: 0.1099 - val_accuracy: 0.9589\n",
      "Epoch 18/50\n",
      " - 1057s - loss: 0.0782 - accuracy: 0.9695 - val_loss: 0.1101 - val_accuracy: 0.9592\n",
      "Train on 32383 samples, validate on 8096 samples\n",
      "Epoch 1/5\n",
      " - 1060s - loss: 0.0792 - accuracy: 0.9687 - val_loss: 0.1107 - val_accuracy: 0.9592\n",
      "Epoch 2/5\n",
      " - 1059s - loss: 0.0764 - accuracy: 0.9699 - val_loss: 0.1143 - val_accuracy: 0.9589\n",
      "Epoch 3/5\n",
      " - 1060s - loss: 0.0737 - accuracy: 0.9711 - val_loss: 0.1172 - val_accuracy: 0.9587\n",
      "\n",
      "Epoch 00003: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-06.\n",
      "Epoch 4/5\n",
      " - 1059s - loss: 0.0695 - accuracy: 0.9729 - val_loss: 0.1176 - val_accuracy: 0.9587\n",
      "Epoch 5/5\n",
      " - 1059s - loss: 0.0687 - accuracy: 0.9731 - val_loss: 0.1187 - val_accuracy: 0.9586\n",
      "Train on 32383 samples, validate on 8096 samples\n",
      "Epoch 1/5\n",
      " - 1059s - loss: 0.0682 - accuracy: 0.9735 - val_loss: 0.1194 - val_accuracy: 0.9584\n",
      "Epoch 2/5\n",
      " - 1059s - loss: 0.0678 - accuracy: 0.9736 - val_loss: 0.1203 - val_accuracy: 0.9585\n",
      "Epoch 3/5\n",
      " - 1059s - loss: 0.0673 - accuracy: 0.9736 - val_loss: 0.1206 - val_accuracy: 0.9585\n",
      "\n",
      "Epoch 00003: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-07.\n",
      "Epoch 4/5\n",
      " - 1059s - loss: 0.0668 - accuracy: 0.9741 - val_loss: 0.1207 - val_accuracy: 0.9585\n",
      "Epoch 5/5\n",
      " - 1059s - loss: 0.0669 - accuracy: 0.9741 - val_loss: 0.1209 - val_accuracy: 0.9585\n",
      "0.9236362649503815\n",
      "Start KFold number 2 from 5\n",
      "Split train:  32383 32383\n",
      "Split valid:  8096 8096\n",
      "Train on 32383 samples, validate on 8096 samples\n",
      "Epoch 1/50\n",
      " - 1054s - loss: 0.3146 - accuracy: 0.9217 - val_loss: 0.1833 - val_accuracy: 0.9291\n",
      "Epoch 2/50\n",
      " - 1057s - loss: 0.1602 - accuracy: 0.9357 - val_loss: 0.1568 - val_accuracy: 0.9371\n",
      "Epoch 3/50\n",
      " - 1057s - loss: 0.1460 - accuracy: 0.9402 - val_loss: 0.1406 - val_accuracy: 0.9437\n",
      "Epoch 4/50\n",
      " - 1057s - loss: 0.1403 - accuracy: 0.9431 - val_loss: 0.1418 - val_accuracy: 0.9418\n",
      "Epoch 5/50\n",
      " - 1057s - loss: 0.1333 - accuracy: 0.9459 - val_loss: 0.1374 - val_accuracy: 0.9443\n",
      "Epoch 6/50\n",
      " - 1057s - loss: 0.1304 - accuracy: 0.9474 - val_loss: 0.1249 - val_accuracy: 0.9495\n",
      "Epoch 7/50\n",
      " - 1056s - loss: 0.1261 - accuracy: 0.9489 - val_loss: 0.1232 - val_accuracy: 0.9510\n",
      "Epoch 8/50\n",
      " - 1057s - loss: 0.1230 - accuracy: 0.9509 - val_loss: 0.1250 - val_accuracy: 0.9511\n",
      "Epoch 9/50\n",
      " - 1056s - loss: 0.1213 - accuracy: 0.9516 - val_loss: 0.1267 - val_accuracy: 0.9498\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 10/50\n",
      " - 1057s - loss: 0.1060 - accuracy: 0.9580 - val_loss: 0.1104 - val_accuracy: 0.9571\n",
      "Epoch 11/50\n",
      " - 1056s - loss: 0.1017 - accuracy: 0.9596 - val_loss: 0.1098 - val_accuracy: 0.9571\n",
      "Epoch 12/50\n",
      " - 1056s - loss: 0.0994 - accuracy: 0.9609 - val_loss: 0.1081 - val_accuracy: 0.9581\n",
      "Epoch 13/50\n",
      " - 1056s - loss: 0.0968 - accuracy: 0.9618 - val_loss: 0.1089 - val_accuracy: 0.9579\n",
      "Epoch 14/50\n",
      " - 1056s - loss: 0.0949 - accuracy: 0.9625 - val_loss: 0.1095 - val_accuracy: 0.9579\n",
      "\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "Epoch 15/50\n",
      " - 1056s - loss: 0.0905 - accuracy: 0.9644 - val_loss: 0.1077 - val_accuracy: 0.9590\n",
      "Epoch 16/50\n",
      " - 1056s - loss: 0.0900 - accuracy: 0.9645 - val_loss: 0.1078 - val_accuracy: 0.9592\n",
      "Epoch 17/50\n",
      " - 1056s - loss: 0.0894 - accuracy: 0.9647 - val_loss: 0.1079 - val_accuracy: 0.9593\n",
      "\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "Epoch 18/50\n",
      " - 1056s - loss: 0.0886 - accuracy: 0.9652 - val_loss: 0.1078 - val_accuracy: 0.9592\n",
      "Epoch 19/50\n",
      " - 1056s - loss: 0.0886 - accuracy: 0.9652 - val_loss: 0.1078 - val_accuracy: 0.9591\n",
      "Train on 32383 samples, validate on 8096 samples\n",
      "Epoch 1/5\n",
      " - 1060s - loss: 0.0919 - accuracy: 0.9637 - val_loss: 0.1089 - val_accuracy: 0.9582\n",
      "Epoch 2/5\n",
      " - 1060s - loss: 0.0895 - accuracy: 0.9646 - val_loss: 0.1085 - val_accuracy: 0.9585\n",
      "Epoch 3/5\n",
      " - 1060s - loss: 0.0869 - accuracy: 0.9658 - val_loss: 0.1096 - val_accuracy: 0.9587\n",
      "Epoch 4/5\n",
      " - 1059s - loss: 0.0845 - accuracy: 0.9666 - val_loss: 0.1115 - val_accuracy: 0.9580\n",
      "\n",
      "Epoch 00004: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-06.\n",
      "Epoch 5/5\n",
      " - 1059s - loss: 0.0785 - accuracy: 0.9691 - val_loss: 0.1119 - val_accuracy: 0.9587\n",
      "Train on 32383 samples, validate on 8096 samples\n",
      "Epoch 1/5\n",
      " - 1060s - loss: 0.0774 - accuracy: 0.9695 - val_loss: 0.1122 - val_accuracy: 0.9588\n",
      "Epoch 2/5\n",
      " - 1059s - loss: 0.0767 - accuracy: 0.9699 - val_loss: 0.1130 - val_accuracy: 0.9587\n",
      "Epoch 3/5\n",
      " - 1059s - loss: 0.0761 - accuracy: 0.9702 - val_loss: 0.1134 - val_accuracy: 0.9585\n",
      "\n",
      "Epoch 00003: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-07.\n",
      "Epoch 4/5\n",
      " - 1060s - loss: 0.0749 - accuracy: 0.9706 - val_loss: 0.1136 - val_accuracy: 0.9586\n",
      "Epoch 5/5\n",
      " - 1060s - loss: 0.0750 - accuracy: 0.9705 - val_loss: 0.1136 - val_accuracy: 0.9586\n",
      "0.9265232594496247\n",
      "Start KFold number 3 from 5\n",
      "Split train:  32383 32383\n",
      "Split valid:  8096 8096\n",
      "Train on 32383 samples, validate on 8096 samples\n",
      "Epoch 1/50\n",
      " - 1053s - loss: 0.2074 - accuracy: 0.9234 - val_loss: 0.1655 - val_accuracy: 0.9321\n",
      "Epoch 2/50\n",
      " - 1057s - loss: 0.1571 - accuracy: 0.9367 - val_loss: 0.1414 - val_accuracy: 0.9427\n",
      "Epoch 3/50\n",
      " - 1057s - loss: 0.1440 - accuracy: 0.9417 - val_loss: 0.1410 - val_accuracy: 0.9442\n",
      "Epoch 4/50\n",
      " - 1058s - loss: 0.1384 - accuracy: 0.9439 - val_loss: 0.1356 - val_accuracy: 0.9446\n",
      "Epoch 5/50\n",
      " - 1059s - loss: 0.1336 - accuracy: 0.9459 - val_loss: 0.1308 - val_accuracy: 0.9464\n",
      "Epoch 6/50\n",
      " - 1058s - loss: 0.1302 - accuracy: 0.9475 - val_loss: 0.1303 - val_accuracy: 0.9480\n",
      "Epoch 7/50\n",
      " - 1058s - loss: 0.1278 - accuracy: 0.9485 - val_loss: 0.1295 - val_accuracy: 0.9481\n",
      "Epoch 8/50\n",
      " - 1057s - loss: 0.1231 - accuracy: 0.9510 - val_loss: 0.1196 - val_accuracy: 0.9530\n",
      "Epoch 9/50\n",
      " - 1057s - loss: 0.1193 - accuracy: 0.9529 - val_loss: 0.1177 - val_accuracy: 0.9546\n",
      "Epoch 10/50\n",
      " - 1057s - loss: 0.1167 - accuracy: 0.9541 - val_loss: 0.1209 - val_accuracy: 0.9528\n",
      "Epoch 11/50\n",
      " - 1057s - loss: 0.1141 - accuracy: 0.9552 - val_loss: 0.1270 - val_accuracy: 0.9492\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 12/50\n",
      " - 1057s - loss: 0.0995 - accuracy: 0.9612 - val_loss: 0.1077 - val_accuracy: 0.9586\n",
      "Epoch 13/50\n",
      " - 1004s - loss: 0.0948 - accuracy: 0.9629 - val_loss: 0.1069 - val_accuracy: 0.9592\n",
      "Epoch 14/50\n",
      " - 610s - loss: 0.0923 - accuracy: 0.9640 - val_loss: 0.1076 - val_accuracy: 0.9594\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/50\n",
      " - 1058s - loss: 0.0899 - accuracy: 0.9647 - val_loss: 0.1076 - val_accuracy: 0.9591\n",
      "\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "Epoch 16/50\n",
      " - 1057s - loss: 0.0860 - accuracy: 0.9664 - val_loss: 0.1075 - val_accuracy: 0.9594\n",
      "Epoch 17/50\n",
      " - 1058s - loss: 0.0852 - accuracy: 0.9668 - val_loss: 0.1078 - val_accuracy: 0.9594\n",
      "Train on 32383 samples, validate on 8096 samples\n",
      "Epoch 1/5\n",
      " - 1061s - loss: 0.0868 - accuracy: 0.9660 - val_loss: 0.1085 - val_accuracy: 0.9591\n",
      "Epoch 2/5\n",
      " - 1060s - loss: 0.0844 - accuracy: 0.9670 - val_loss: 0.1095 - val_accuracy: 0.9591\n",
      "Epoch 3/5\n",
      " - 1059s - loss: 0.0815 - accuracy: 0.9681 - val_loss: 0.1106 - val_accuracy: 0.9591\n",
      "\n",
      "Epoch 00003: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-06.\n",
      "Epoch 4/5\n",
      " - 1060s - loss: 0.0767 - accuracy: 0.9701 - val_loss: 0.1114 - val_accuracy: 0.9593\n",
      "Epoch 5/5\n",
      " - 1059s - loss: 0.0759 - accuracy: 0.9704 - val_loss: 0.1123 - val_accuracy: 0.9591\n",
      "Train on 32383 samples, validate on 8096 samples\n",
      "Epoch 1/5\n",
      " - 1059s - loss: 0.0752 - accuracy: 0.9707 - val_loss: 0.1126 - val_accuracy: 0.9591\n",
      "Epoch 2/5\n",
      " - 1059s - loss: 0.0750 - accuracy: 0.9707 - val_loss: 0.1130 - val_accuracy: 0.9591\n",
      "Epoch 3/5\n",
      " - 1058s - loss: 0.0743 - accuracy: 0.9710 - val_loss: 0.1133 - val_accuracy: 0.9591\n",
      "\n",
      "Epoch 00003: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-07.\n",
      "Epoch 4/5\n",
      " - 1058s - loss: 0.0738 - accuracy: 0.9713 - val_loss: 0.1135 - val_accuracy: 0.9590\n",
      "Epoch 5/5\n",
      " - 1058s - loss: 0.0739 - accuracy: 0.9713 - val_loss: 0.1135 - val_accuracy: 0.9590\n",
      "0.9279588750949337\n",
      "Start KFold number 4 from 5\n",
      "Split train:  32383 32383\n",
      "Split valid:  8096 8096\n",
      "Train on 32383 samples, validate on 8096 samples\n",
      "Epoch 1/50\n",
      " - 615s - loss: 0.1953 - accuracy: 0.9240 - val_loss: 0.1626 - val_accuracy: 0.9300\n",
      "Epoch 2/50\n",
      " - 1057s - loss: 0.1568 - accuracy: 0.9367 - val_loss: 0.1463 - val_accuracy: 0.9401\n",
      "Epoch 3/50\n",
      " - 1057s - loss: 0.1464 - accuracy: 0.9408 - val_loss: 0.1383 - val_accuracy: 0.9444\n",
      "Epoch 4/50\n",
      " - 1057s - loss: 0.1397 - accuracy: 0.9432 - val_loss: 0.1372 - val_accuracy: 0.9429\n",
      "Epoch 5/50\n",
      " - 1057s - loss: 0.1365 - accuracy: 0.9452 - val_loss: 0.1329 - val_accuracy: 0.9460\n",
      "Epoch 6/50\n",
      " - 1057s - loss: 0.1307 - accuracy: 0.9475 - val_loss: 0.1318 - val_accuracy: 0.9461\n",
      "Epoch 7/50\n",
      " - 1057s - loss: 0.1284 - accuracy: 0.9484 - val_loss: 0.1277 - val_accuracy: 0.9493\n",
      "Epoch 8/50\n",
      " - 1057s - loss: 0.1244 - accuracy: 0.9506 - val_loss: 0.1238 - val_accuracy: 0.9511\n",
      "Epoch 9/50\n",
      " - 1057s - loss: 0.1212 - accuracy: 0.9520 - val_loss: 0.1238 - val_accuracy: 0.9514\n",
      "Epoch 10/50\n",
      " - 1056s - loss: 0.1187 - accuracy: 0.9531 - val_loss: 0.1169 - val_accuracy: 0.9540\n",
      "Epoch 11/50\n",
      " - 1057s - loss: 0.1142 - accuracy: 0.9549 - val_loss: 0.1188 - val_accuracy: 0.9539\n",
      "Epoch 12/50\n",
      " - 1057s - loss: 0.1118 - accuracy: 0.9559 - val_loss: 0.1322 - val_accuracy: 0.9489\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 13/50\n",
      " - 1057s - loss: 0.0981 - accuracy: 0.9617 - val_loss: 0.1084 - val_accuracy: 0.9583\n",
      "Epoch 14/50\n",
      " - 1056s - loss: 0.0930 - accuracy: 0.9634 - val_loss: 0.1090 - val_accuracy: 0.9584\n",
      "Epoch 15/50\n",
      " - 1057s - loss: 0.0903 - accuracy: 0.9648 - val_loss: 0.1092 - val_accuracy: 0.9584\n",
      "\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "Epoch 16/50\n",
      " - 1056s - loss: 0.0869 - accuracy: 0.9659 - val_loss: 0.1088 - val_accuracy: 0.9588\n",
      "Epoch 17/50\n",
      " - 1056s - loss: 0.0863 - accuracy: 0.9663 - val_loss: 0.1090 - val_accuracy: 0.9589\n",
      "Train on 32383 samples, validate on 8096 samples\n",
      "Epoch 1/5\n",
      " - 1060s - loss: 0.0874 - accuracy: 0.9659 - val_loss: 0.1100 - val_accuracy: 0.9588\n",
      "Epoch 2/5\n",
      " - 1059s - loss: 0.0851 - accuracy: 0.9668 - val_loss: 0.1102 - val_accuracy: 0.9586\n",
      "Epoch 3/5\n",
      " - 1059s - loss: 0.0824 - accuracy: 0.9677 - val_loss: 0.1129 - val_accuracy: 0.9583\n",
      "\n",
      "Epoch 00003: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-06.\n",
      "Epoch 4/5\n",
      " - 1059s - loss: 0.0784 - accuracy: 0.9694 - val_loss: 0.1120 - val_accuracy: 0.9587\n",
      "Epoch 5/5\n",
      " - 1059s - loss: 0.0779 - accuracy: 0.9697 - val_loss: 0.1123 - val_accuracy: 0.9589\n",
      "Train on 32383 samples, validate on 8096 samples\n",
      "Epoch 1/5\n",
      " - 1059s - loss: 0.0774 - accuracy: 0.9699 - val_loss: 0.1126 - val_accuracy: 0.9587\n",
      "Epoch 2/5\n",
      " - 1059s - loss: 0.0769 - accuracy: 0.9700 - val_loss: 0.1132 - val_accuracy: 0.9586\n",
      "Epoch 3/5\n",
      " - 1059s - loss: 0.0766 - accuracy: 0.9701 - val_loss: 0.1134 - val_accuracy: 0.9585\n",
      "\n",
      "Epoch 00003: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-07.\n",
      "Epoch 4/5\n",
      " - 1059s - loss: 0.0760 - accuracy: 0.9705 - val_loss: 0.1134 - val_accuracy: 0.9586\n",
      "Epoch 5/5\n",
      " - 1059s - loss: 0.0760 - accuracy: 0.9706 - val_loss: 0.1133 - val_accuracy: 0.9587\n",
      "0.9258502938795087\n",
      "Start KFold number 5 from 5\n",
      "Split train:  32384 32384\n",
      "Split valid:  8095 8095\n",
      "Train on 32384 samples, validate on 8095 samples\n",
      "Epoch 1/50\n",
      " - 1058s - loss: 0.1983 - accuracy: 0.9267 - val_loss: 0.1561 - val_accuracy: 0.9362\n",
      "Epoch 2/50\n",
      " - 1060s - loss: 0.1471 - accuracy: 0.9407 - val_loss: 0.1374 - val_accuracy: 0.9457\n",
      "Epoch 3/50\n",
      " - 1060s - loss: 0.1386 - accuracy: 0.9437 - val_loss: 0.1384 - val_accuracy: 0.9441\n",
      "Epoch 4/50\n",
      " - 1063s - loss: 0.1353 - accuracy: 0.9457 - val_loss: 0.1307 - val_accuracy: 0.9474\n",
      "Epoch 5/50\n",
      " - 1063s - loss: 0.1299 - accuracy: 0.9477 - val_loss: 0.1321 - val_accuracy: 0.9477\n",
      "Epoch 6/50\n",
      " - 1061s - loss: 0.1282 - accuracy: 0.9486 - val_loss: 0.1257 - val_accuracy: 0.9507\n",
      "Epoch 7/50\n",
      " - 1060s - loss: 0.1241 - accuracy: 0.9507 - val_loss: 0.1210 - val_accuracy: 0.9528\n",
      "Epoch 8/50\n",
      " - 1059s - loss: 0.1211 - accuracy: 0.9522 - val_loss: 0.1211 - val_accuracy: 0.9530\n",
      "Epoch 9/50\n",
      " - 1061s - loss: 0.1172 - accuracy: 0.9538 - val_loss: 0.1184 - val_accuracy: 0.9537\n",
      "Epoch 10/50\n",
      " - 1062s - loss: 0.1136 - accuracy: 0.9556 - val_loss: 0.1210 - val_accuracy: 0.9523\n",
      "Epoch 11/50\n",
      " - 1060s - loss: 0.1139 - accuracy: 0.9553 - val_loss: 0.1183 - val_accuracy: 0.9553\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 12/50\n",
      " - 1062s - loss: 0.1001 - accuracy: 0.9607 - val_loss: 0.1066 - val_accuracy: 0.9586\n",
      "Epoch 13/50\n",
      " - 1059s - loss: 0.0944 - accuracy: 0.9631 - val_loss: 0.1060 - val_accuracy: 0.9593\n",
      "Epoch 14/50\n",
      " - 1062s - loss: 0.0910 - accuracy: 0.9645 - val_loss: 0.1061 - val_accuracy: 0.9598\n",
      "Epoch 15/50\n",
      " - 1062s - loss: 0.0883 - accuracy: 0.9655 - val_loss: 0.1066 - val_accuracy: 0.9596\n",
      "\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "Epoch 16/50\n",
      " - 1061s - loss: 0.0837 - accuracy: 0.9672 - val_loss: 0.1064 - val_accuracy: 0.9597\n",
      "Epoch 17/50\n",
      " - 1060s - loss: 0.0830 - accuracy: 0.9673 - val_loss: 0.1068 - val_accuracy: 0.9597\n",
      "Train on 32384 samples, validate on 8095 samples\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": " OOM when allocating tensor with shape[64,64,64,64] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node gradients_13/vgg19_4/block1_conv2/convolution_grad/Conv2DBackpropInput (defined at C:\\Users\\HP\\miniconda3\\envs\\nlpp\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py:1751) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n [Op:__inference_keras_scratch_graph_592906]\n\nFunction call stack:\nkeras_scratch_graph\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-fccb9545d26e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             model.fit(x = X_train, y= Y_train, validation_data=(X_valid, Y_valid),\n\u001b[1;32m---> 66\u001b[1;33m                   batch_size= batch_size, verbose=2, epochs=epochs,callbacks=callbacks,shuffle=True)\n\u001b[0m\u001b[0;32m     67\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misfile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkfold_weights_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\nlpp\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1239\u001b[1;33m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[0;32m   1240\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1241\u001b[0m     def evaluate(self,\n",
      "\u001b[1;32m~\\miniconda3\\envs\\nlpp\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[0;32m    194\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 196\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    197\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\nlpp\\lib\\site-packages\\tensorflow_core\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   3738\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3739\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3740\u001b[1;33m     \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3741\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3742\u001b[0m     \u001b[1;31m# EagerTensor.numpy() will often make a copy to ensure memory safety.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\nlpp\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1079\u001b[0m       \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mFor\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0mpositional\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mkeyword\u001b[0m \u001b[0margument\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1080\u001b[0m     \"\"\"\n\u001b[1;32m-> 1081\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1082\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1083\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\nlpp\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1119\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[0;32m   1120\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[1;32m-> 1121\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1122\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1123\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\nlpp\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1222\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1223\u001b[0m       flat_outputs = forward_function.call(\n\u001b[1;32m-> 1224\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[0;32m   1225\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1226\u001b[0m       \u001b[0mgradient_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_delayed_rewrite_functions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\nlpp\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    509\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    510\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"executor_type\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"config_proto\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 511\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    512\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    513\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32m~\\miniconda3\\envs\\nlpp\\lib\\site-packages\\tensorflow_core\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m     \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m     keras_symbolic_tensors = [\n",
      "\u001b[1;32m~\\miniconda3\\envs\\nlpp\\lib\\site-packages\\six.py\u001b[0m in \u001b[0;36mraise_from\u001b[1;34m(value, from_value)\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m:  OOM when allocating tensor with shape[64,64,64,64] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node gradients_13/vgg19_4/block1_conv2/convolution_grad/Conv2DBackpropInput (defined at C:\\Users\\HP\\miniconda3\\envs\\nlpp\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py:1751) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n [Op:__inference_keras_scratch_graph_592906]\n\nFunction call stack:\nkeras_scratch_graph\n"
     ]
    }
   ],
   "source": [
    "for train_index, test_index in kf.split(x_train):\n",
    "        start_time_model_fitting = time.time()\n",
    "        \n",
    "        X_train = x_train[train_index]\n",
    "        Y_train = y_train[train_index]\n",
    "        X_valid = x_train[test_index]\n",
    "        Y_valid = y_train[test_index]\n",
    "\n",
    "        num_fold += 1\n",
    "        print('Start KFold number {} from {}'.format(num_fold, nfolds))\n",
    "        print('Split train: ', len(X_train), len(Y_train))\n",
    "        print('Split valid: ', len(X_valid), len(Y_valid))\n",
    "        \n",
    "        kfold_weights_path = os.path.join('', 'weights_kfold_' + str(num_fold) + '.h5')\n",
    "        \n",
    "        base_model = VGG19(include_top=False,\n",
    "                       weights='imagenet',\n",
    "                       input_shape=(input_size,input_size,input_channels))\n",
    "        \n",
    "        model = Sequential()\n",
    "        model.add(BatchNormalization(input_shape=(input_size, input_size,input_channels)))\n",
    "        model.add(base_model)\n",
    "        '''model.add(Conv2D(32, kernel_size=(3, 3),padding='same', activation='relu'))\n",
    "        model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "        model.add(Dropout(0.25))\n",
    "\n",
    "        model.add(Conv2D(64, kernel_size=(3, 3),padding='same', activation='relu'))\n",
    "        model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "        model.add(Dropout(0.25))\n",
    "        \n",
    "        model.add(Conv2D(128, kernel_size=(3, 3),padding='same', activation='relu'))\n",
    "        model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "        model.add(Dropout(0.25))\n",
    "        \n",
    "        model.add(Conv2D(256, kernel_size=(3, 3),padding='same', activation='relu'))\n",
    "        model.add(Conv2D(256, (3, 3), activation='relu'))\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "        model.add(Dropout(0.25))\n",
    "        '''\n",
    "        model.add(Flatten())\n",
    "        #model.add(Dense(512, activation='relu'))\n",
    "        #model.add(BatchNormalization())\n",
    "        #model.add(Dropout(0.5))\n",
    "        model.add(Dense(17, activation='sigmoid'))\n",
    "\n",
    "        epochs_arr = [50, 5, 5]\n",
    "        learn_rates = [0.001, 0.0001, 0.00001]\n",
    "\n",
    "        for learn_rate, epochs in zip(learn_rates, epochs_arr):\n",
    "            opt  = optimizers.Adam(lr=learn_rate)\n",
    "            model.compile(loss='binary_crossentropy', # We NEED binary here, since categorical_crossentropy l1 norms the output before calculating loss.\n",
    "                          optimizer=opt,\n",
    "                          metrics=['accuracy'])\n",
    "            callbacks = [EarlyStopping(monitor='val_loss', patience=4, verbose=0),\n",
    "                         ReduceLROnPlateau(monitor='val_loss',\n",
    "                                   factor=0.1,\n",
    "                                   patience=2,\n",
    "                                   cooldown=2,\n",
    "                                   verbose=1),\n",
    "            ModelCheckpoint(kfold_weights_path, monitor='val_loss', save_best_only=True, verbose=0)]\n",
    "\n",
    "            model.fit(x = X_train, y= Y_train, validation_data=(X_valid, Y_valid),\n",
    "                  batch_size= batch_size, verbose=2, epochs=epochs,callbacks=callbacks,shuffle=True)\n",
    "        \n",
    "        if os.path.isfile(kfold_weights_path):\n",
    "            model.load_weights(kfold_weights_path)\n",
    "        \n",
    "        p_valid = model.predict(X_valid, batch_size = batch_size, verbose=4)\n",
    "        print(fbeta_score(Y_valid, np.array(p_valid) > 0.2, beta=4, average='samples'))\n",
    "\n",
    "        p_train = model.predict(x_train, batch_size =batch_size, verbose=4)\n",
    "        yfull_train.append(p_train)\n",
    "        \n",
    "        p_test = model.predict(x_test, batch_size = batch_size, verbose=4)\n",
    "        yfull_test.append(p_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = np.array(yfull_test[0])\n",
    "for i in range(1, nfolds):\n",
    "    result += np.array(yfull_test[i])\n",
    "result /= nfolds\n",
    "result = pd.DataFrame(result, columns = labels)\n",
    "result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "thres = [0.07, 0.17, 0.2, 0.04, 0.23, 0.33, 0.24, 0.22, 0.1, 0.19, 0.23, 0.24, 0.12, 0.14, 0.25, 0.26, 0.16]\n",
    "preds = []\n",
    "for i in tqdm(range(result.shape[0]), miniters=1000):\n",
    "    a = result.iloc[[i]]\n",
    "    a = a.apply(lambda x: x > 0.2, axis=1)\n",
    "    a = a.transpose()\n",
    "    a = a.loc[a[i] == True]\n",
    "    ' '.join(list(a.index))\n",
    "    preds.append(' '.join(list(a.index)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['tags'] = preds\n",
    "df_test.to_csv('submission_keras55.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
